{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score,KFold,train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_dist                     0\n",
      "avg_rating_by_driver       201\n",
      "avg_rating_of_driver      8122\n",
      "avg_surge                    0\n",
      "city                         0\n",
      "last_trip_date               0\n",
      "phone                      396\n",
      "signup_date                  0\n",
      "surge_pct                    0\n",
      "trips_in_first_30_days       0\n",
      "luxury_car_user              0\n",
      "weekday_pct                  0\n",
      "dtype: int64\n",
      "Total number of rows in this Dataset:  50000\n"
     ]
    }
   ],
   "source": [
    "print df.isnull().sum()  # missing values for each column\n",
    "print \"Total number of rows in this Dataset: \", df.count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_dtypes_df(df,datetime='%Y-%m-%d',use_datetime=False):\n",
    "    # Either the values are numbers, datetime, or strings (if string can remain as objects)\n",
    "    for column in df.columns:\n",
    "        try:\n",
    "            df[column] = df[column].astype(float)\n",
    "        except:\n",
    "            try:\n",
    "                if use_datetime==True:\n",
    "                    df[column] = pd.to_datetime(df[column],format=datetime)\n",
    "                else: \n",
    "                    print \"Couldn't convert columns: \", column, \" so leaving it as object dtype\"\n",
    "            except:\n",
    "                print \"Couldn't convert columns: \", column, \" so leaving it as object dtype\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_target(df):\n",
    "    y = (df['last_trip_date'] < datetime.datetime(2014,6,1)).astype(int).rename('response')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAssumptions:\\n1. ratings_by_driver is a good representation of the ride\\n2. where missing, an average rating of all ratings is a good representation of the missing rating\\n3. not using last_trip column because response variable is directly measured from this - multicollinearity\\n4. not using signup_date because all dates are from January by design in this dataset.\\n5. not using phone because too much variation. Might lemmatize later or something.\\n'"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_split_df(X_df,test_size=0.25):\n",
    "    \n",
    "    X_df = set_dtypes_df(X_df,use_datetime=True)\n",
    "    \n",
    "    # Create response variable\n",
    "    y_df = make_target(X_df)\n",
    "    \n",
    "    # replace missing of_driver ratings with the by_driver ratings if available\n",
    "    mask = X_df['avg_rating_of_driver'].isnull()\n",
    "    X_df.loc[:,'avg_rating_of_driver'][mask] = X_df.loc[:,'avg_rating_by_driver'][mask]\n",
    "    \n",
    "    # set remaining missing ratings to their column averages\n",
    "    mask1_of = X_df['avg_rating_of_driver'].isnull()\n",
    "    mask1_by = X_df['avg_rating_by_driver'].isnull()\n",
    "    X_df['avg_rating_of_driver'][mask1_of] = X_df['avg_rating_of_driver'].mean()\n",
    "    X_df['avg_rating_by_driver'][mask1_by] = X_df['avg_rating_by_driver'].mean()\n",
    "    \n",
    "    # drop these columns as they're not useful, see assumptions below\n",
    "    X_df = X_df.drop(['phone','last_trip_date','signup_date'],axis=1)\n",
    "    \n",
    "    # dummify city column\n",
    "    X_df = pd.get_dummies(X_df,columns=['city'])\n",
    "    \n",
    "    #train_test_split, user can pass argument to increase test_size\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_df,y_df,test_size=test_size)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "'''\n",
    "Assumptions:\n",
    "1. ratings_by_driver is a good representation of the ride\n",
    "2. where missing, an average rating of all ratings is a good representation of the missing rating\n",
    "3. not using last_trip column because response variable is directly measured from this - multicollinearity\n",
    "4. not using signup_date because all dates are from January by design in this dataset.\n",
    "5. not using phone because too much variation. Might lemmatize later or something.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't convert columns:  city  so leaving it as object dtype\n",
      "Couldn't convert columns:  phone  so leaving it as object dtype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aamir/.local/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/aamir/.local/lib/python2.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/aamir/.local/lib/python2.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = clean_split_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>surge_pct</th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>luxury_car_user</th>\n",
       "      <th>weekday_pct</th>\n",
       "      <th>city_Astapor</th>\n",
       "      <th>city_King's Landing</th>\n",
       "      <th>city_Winterfell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44701</th>\n",
       "      <td>3.50</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39091</th>\n",
       "      <td>3.33</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41782</th>\n",
       "      <td>2.72</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>9.93</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.11</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>2.62</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_dist  avg_rating_by_driver  avg_rating_of_driver  avg_surge  \\\n",
       "44701      3.50                   4.5                   4.4       1.00   \n",
       "39091      3.33                   3.5                   4.5       1.00   \n",
       "41782      2.72                   5.0                   4.7       1.00   \n",
       "3345       9.93                   4.9                   4.7       1.11   \n",
       "1928       2.62                   5.0                   4.0       1.00   \n",
       "\n",
       "       surge_pct  trips_in_first_30_days  luxury_car_user  weekday_pct  \\\n",
       "44701        0.0                     2.0              1.0         41.7   \n",
       "39091        0.0                     0.0              1.0          0.0   \n",
       "41782        0.0                     3.0              1.0        100.0   \n",
       "3345         6.9                     2.0              1.0         86.2   \n",
       "1928         0.0                     0.0              0.0        100.0   \n",
       "\n",
       "       city_Astapor  city_King's Landing  city_Winterfell  \n",
       "44701             0                    0                1  \n",
       "39091             0                    0                1  \n",
       "41782             0                    0                1  \n",
       "3345              1                    0                0  \n",
       "1928              1                    0                0  "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()  #clean and full matrix, ready for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23420\n",
       "0    14080\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()  # this class imbalance isn't too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('surge_pct', 0.11199606123768718),\n",
       " ('avg_surge', 0.00097298345567489513),\n",
       " ('city_Astapor', 0.00021828475721517339),\n",
       " ('city_Winterfell', 0.00010785860318650092),\n",
       " ('avg_rating_by_driver', -0.00024837859137594176),\n",
       " ('avg_rating_of_driver', -0.00029681391147539857),\n",
       " (\"city_King's Landing\", -0.00032614336040167387),\n",
       " ('luxury_car_user', -0.00056008323933226609),\n",
       " ('trips_in_first_30_days', -0.0051884288787581445),\n",
       " ('avg_dist', -0.017053716808244627),\n",
       " ('weekday_pct', -0.99354796430991266)]"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a little PCA to figure out where the highest variance is.\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "sorted(zip(X_train.columns,pca.components_[0]), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```` This looks interesting because it shows that surge_pct contributes the most to the direction of the first eigenvector. However, if you look at this column, you can quickly realize it's because surge_pct is 0 when there is no surge and only becomes non-zero when there is a surge. So this makes sense (Even the second eigenvector shows surge_pct at the top). It may still be a good predictor intuitively though. Customers that have used surge_pct before may very well be more likely to stay customers as they are showing dependency on the app, are less likely to take the train to save money etc. ```` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37500, 11)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta=1, eta=0.1, init=None, l1_ratio=0.0, max_iter=10,\n",
       "  n_components=5, nls_max_iter=2000, random_state=None, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a little NNMF to get more of an interpretable sense of the inputs\n",
    "nmf = NMF(n_components=5, max_iter=10)\n",
    "nmf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse(W, H, V):\n",
    "    a = (V - (W.dot(H)))\n",
    "    a = np.array(a)**2\n",
    "    return np.sum(a) / reduce(lambda x, y: x*y, V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.107151911806\n"
     ]
    }
   ],
   "source": [
    "W, H = nmf.transform(X), nmf.components_\n",
    "print mse(W,H,X)  # so 5 dimensions describe our input matrix quite well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
